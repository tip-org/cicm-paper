\documentclass{llncs}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,calc}


%\usepackage{url}
\usepackage{multirow}
\usepackage{listings}
\usepackage{amsmath}  % for equation*
\usepackage{array}    % for tabular
\usepackage{verbatim} % for comment
\usepackage{wrapfig}
\usepackage[final]{microtype}
\usepackage[pdfborder={0 0 0}]{hyperref}
\usepackage{tabularx}

\newcommand\forAll[1]{\forall \, #1 \, . \,}
\newcommand\forAllII[2]{\forall \, #1 \, #2 \, . \,}

\newcommand\propno[1]{(\emph{#1})}
\newcommand\hs[1]{\texttt{#1}}

% \raggedbottom

\lstnewenvironment{code}[1][]
  {\noindent
   \vspace{-0.5\baselineskip}
   \lstset{basicstyle=\ttfamily,
           frame=single,
           language=Haskell,
           keywordstyle=\color{black},
           #1}
   \fontsize{8pt}{8pt}\selectfont}
  {}

\newcommand\NOTE[1]{} % \mbox{}\marginpar{\fontsize{8pt}{8pt}\selectfont\raggedright\hspace{0pt}\emph{#1}}}

\def\maindocument{} % To tell tikz images that they are not stand alone

\begin{document}

\title{TIP: Tons of Inductive Problems}

\author{Moa Johansson \and Dan Ros\'en \and Nicholas Smallbone \and Koen Claessen}
\institute{Department of Computer Science and Engineering, Chalmers University of Technology
	\email{\{jomoa,danr,nicsma,koen\}@chalmers.se}
	}

\authorrunning{Johansson, Ros\'en, Smallbone, Claessen}
\titlerunning{}

\maketitle

\begin{abstract}
There has recently been increased interest in inductive theorem
proving, both in special-purpose provers such as
IsaPlanner, Zeno and HipSpec, and in SMT-solvers such as
Dafny/Z3 and CVC4. To ease evaluation and comparison between systems,
good benchmarks are important. However, there has not been a shared
standard benchmark suite for inductive theorem provers. This paper
describes initial efforts to collect benchmarks for inductive theorem
provers which can be shared among developers and users.
We expect this benchmark suite to continuously grow as
more problems are submitted by the community. New challenge problems
will promote new developments of provers which will greatly benefit
both developers and users of inductive theorem provers.

\end{abstract}

\section{Introduction}

We have recently seen increased interest in inductive theorem proving, both with specialised provers such as IsaPlanner, Zeno and HipSpec \cite{dixon2007isaplanner,zeno,hipspecCADE}, SMT-solvers such as Dafny/Z3 and CVC4 \cite{dafny,cvc4}, recent work on the first-order SPASS prover \cite{SPASSInduction}, as well as some support in proof assistants \cite{acl2,hipster}.

To ease evaluation and development, and compare the relative strengths of the different systems, it is important to have good standard benchmarks. The contribution of this paper is an accessible standard benchmark suite for inductive theorem provers which can be extended by users and developers. The benchmarks are publicly available at:
\begin{center}
\url{https://github.com/tip-org/benchmarks}
\end{center}
We have so far collected 197 problems in the TIP benchmark suite. We invite the community to submit additional problems and challenges and expect the collection to continuously grow, and provide new challenges for developers.

%% We do not yet discuss any special-purpose language features for expressing inductive problems in general. The benchmarks are therefore currently expressed in a subset of the WhyML specification language from the Why3 program verification system \cite{boogie11why3,Why3}. We have chosen this format as the Why3 system already provides translation tools from WhyML to various other common formats, such as SMT-LIB and versions of TPTP.
%% In addition, the WhyML language is easy to read also for humans. The Why3 system relies on external provers to discharge proof obligations and is already connected to a wide variety of automated and interactive provers, including  Alt-Ergo, CVC3, Z3, E, SPASS, Vampire, Coq and PVS. We hope that the new benchmark suite will encourage the connection of automated inductive theorem provers to Why3.

\section{The Benchmark Format}
\label{sec:format}
Our benchmarks are expressed in an extension of the SMT-LIB format
\cite{BST10}. We extend the format so that it can express inductive
problems natively; using encodings throws away metainformation that
can be useful to tools. Wherever possible, we use existing extensions
instead of designing our own. We use the following existing extensions:
\begin{itemize}
\item The \verb|declare-datatypes| syntax for declaring algebraic
  datatypes, which is supported in Z3 and CVC4.
\item The \verb|defines-funs-rec| syntax for recursive function
  definitions, which is implemented in CVC4 and proposed for
  SMT-LIB 2.5 \cite{BST10}.
\item The \verb|par| syntax for polymorphism \cite{cvc4parPR}, which
  is implemented in a version of CVC4.
\end{itemize}

We also add some extensions of our own, which are described fully in
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX:
\begin{itemize}
\item Pattern matching on algebraic datatypes, where traditional
  SMT-LIB requires use of functions like \verb|head| and \verb|tail|.
\item Higher-order functions and lambda functions.
\item A syntactic construct \verb|(assert-not p)| which is
  semantically equivalent to \verb|(assert (not p))| but is intended
  to mark \verb|p| as the goal to prove. (Inductive theorem provers
  often work on a distinguished goal, unlike first-order provers.)
\end{itemize}

To encourage uptake of the format, we have written a tool which can
currently:
\begin{itemize}
\item translate away our own extensions to SMT-LIB, yielding a problem
  which can be read by CVC4,
\item translate a TIP problem to Why3, and
\item translate Haskell programs to TIP.
\end{itemize}

\subsection*{Example}
As an example of what the benchmarks look like, consider \texttt{prop12} from the IsaPlanner benchmark set (see \ref{sec:isap} below), which states that the functions \texttt{drop} and \texttt{map} distribute over one another: \begin{center} \texttt{drop n (map f xs) = map f (drop n xs)}.\end{center}
We declare two simple algebraic datatypes representing natural numbers and polymorphic lists.

\begin{code}
(declare-datatypes (a)
  ((list (nil) (cons (head a) (tail (list a))))))
(declare-datatypes () ((Nat (Z) (S (p Nat)))))
\end{code}

Next, we declare two recursive functions: \texttt{drop}, which recursively drops a given number of elements from the front of the list and \texttt{map}, which is a higher-order function applying the given unary function \texttt{f} to each element of a list.

\begin{code}
(define-funs-rec
  ((par (a b) (map ((f (=> a b)) (xs (list a))) (list b))))
  ((match xs
     (case nil (as nil (list b)))
     (case (cons y ys) (cons (@ f y) (map f ys))))))
(define-funs-rec
  ((par (a) (drop ((n Nat) (xs (list a))) (list a))))
  ((match n
     (case Z xs)
     (case (S m)
       (match xs
         (case nil xs)
         (case (cons y ys) (drop m ys)))))))
\end{code}

Finally, the benchmark problem itself is declared with the keyword \texttt{assert-not}:

\begin{code}
(assert-not
  (par (a b)
    (forall ((n Nat) (f (=> a b)) (xs (list a)))
      (= (drop n (map f xs)) (map f (drop n xs))))))
(check-sat)
\end{code}
Each benchmark file is stand-alone and only contains one property.

\section{Sample Benchmarks}
In this section we give a short overview of  some the problems currently available in the repository. We expect more to be added.

\subsection{IsaPlanner's Rippling and Case-Analysis Benchmarks}
\label{sec:isap}
This set of 85 problems comes from the evaluation of IsaPlanner's rippling-heuristic for guiding rewriting in inductive proofs in the context of functions with case- and if-statements \cite{IsaPcase}. It has been used in the evaluation of many of the recent inductive theorem provers and includes theorems about lists, natural numbers and binary trees. The proofs are relatively easy, most of the theorems can be proved by structural induction using only the function definitions and only 15 require auxiliary lemmas to be discovered.

\subsection{Productive Use of Failure Benchmarks}
This is another benchmark suite which has been used to evaluate several recent provers. It consists of 50 theorems about lists and natural numbers and originates from evaluation of techniques for discovering auxiliary lemmas in the CLAM prover \cite{productiveuse}. The original paper did not provide definitions for the functions used in the benchmarks, so the definitions provided here come from the evaluation of the HipSpec system \cite{hipspecCADE}. These proofs are generally a bit harder, and may require additional lemmas to be found and proved (by another induction) or generalisation of the conjecture in order to strengthen the inductive hypothesis.

\subsection{New TIP Benchmarks}
This set contains 63 new benchmarks including, amongst others,
properties of the Agda standard
library\footnote{\url{https://github.com/agda/agda-stdlib}}
implementation of integers on top of natural numbers, problems about natural numbers in binary representation, problems about regular expressions, binary search trees, grammars and skew heaps. The problems about regular expressions, grammars and heaps have to our knowledge not been fully automated yet and are offered as challenges!

\section{Contribute to TIP}
We invite the theorem proving community to contribute additional inductive benchmarks and challenge problems to TIP. Instructions for how to submit new problems can be found in the TIP repository README file (see \url{https://github.com/tip-org/benchmarks}).

For automated translation from Haskell to out SMT-LIB format, and to a simplified version of it and to Why3, we provide some useful tools which can be found at \url{https://github.com/tip-org/tools}.

\section{Conclusion and Further Work}
TIP is intended to be a standard benchmark suite for developers and users of inductive theorem provers. We hope that this initiative will ease comparison and evaluation of systems and spur further collaboration and development by attracting submissions of additional challenge problems from the community.

In addition to serving as a standard benchmark suite for inductive provers, the TIP benchmarks may also be useful for developers of theory exploration systems. Theory exploration is a technique for automatically discovering interesting conjectures about a given set of functions and datatypes, and is used in for example the HipSpec prover to discover lemmas. The TIP benchmarks can be compared to the output from the theory explorer in precision/recall analysis to assess the quality and interestingness of the conjectures generated. A good theory exploration system may also be used to generate new benchmarks for TIP.

The TIP benchmarks are currently expressed in a subset of WhyML. If we want to use the Why3 translation tools to other formats, there are some restrictions. Functions are for instance required to be provably terminating by the Why3 termination checker, which might not always be the case (e.g. it fails to prove termination for many functions that are not structurally recursive).
In the future, we therefore expect to support a richer language, and will provide tools to help developers use the TIP format.
We may also want to include problems about lazy functions and will then need to extend the format to also allow non-terminating functions.
%We may in the future perhaps also want to include problems featuring functions in a programming language with lazy evaluation.
Another extension is to also allow non-theorems among the benchmarks, for evaluation of tools for counter-example finding.  We see this paper as a starting point to encourage further discussion in the inductive theorem proving community about what future format(s) for inductive problems should look like.



\bibliographystyle{plain}
\bibliography{bibfile}

\end{document}
