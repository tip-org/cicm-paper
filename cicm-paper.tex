\documentclass{llncs}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,calc}


%\usepackage{url}
\usepackage{multirow}
\usepackage{listings}
\usepackage{amsmath}  % for equation*
\usepackage{array}    % for tabular
\usepackage{verbatim} % for comment
\usepackage{wrapfig}
\usepackage[final]{microtype}
\usepackage[pdfborder={0 0 0}]{hyperref}
\usepackage{tabularx}

\newcommand\forAll[1]{\forall \, #1 \, . \,}
\newcommand\forAllII[2]{\forall \, #1 \, #2 \, . \,}

\newcommand\propno[1]{(\emph{#1})}
\newcommand\hs[1]{\texttt{#1}}

% \raggedbottom

\lstnewenvironment{code}[1][]
  {\noindent
   \vspace{-0.5\baselineskip}
   \lstset{basicstyle=\ttfamily,
           frame=single,
           language=Haskell,
           keywordstyle=\color{black},
           #1}
   \fontsize{8pt}{8pt}\selectfont}
  {}

\newcommand\NOTE[1]{} % \mbox{}\marginpar{\fontsize{8pt}{8pt}\selectfont\raggedright\hspace{0pt}\emph{#1}}}

\def\maindocument{} % To tell tikz images that they are not stand alone

\begin{document}

\title{TIP: Tons of Inductive Problems}

\author{Moa Johansson \and Dan Ros\'en \and Nicholas Smallbone \and Koen Claessen}
\institute{Department of Computer Science and Engineering, Chalmers University of Technology
	\email{\{jomoa,danr,nicsma,koen\}@chalmers.se}
	}

\authorrunning{Johansson, Ros\'en, Smallbone, Claessen}
\titlerunning{}

\maketitle

\begin{abstract}
There has recently been increased interest in inductive theorem
proving, both in special-purpose provers such as
IsaPlanner, Zeno and HipSpec, and in SMT-solvers such as
Dafny/Z3 and CVC4. To ease evaluation and comparison between systems,
good benchmarks are important. However, there has not been a shared
standard benchmark suite for inductive theorem provers. This paper
describes initial efforts to collect benchmarks for inductive theorem
provers which can be shared among developers and users. 
We expect this benchmark suite to continuously grow as
more problems are submitted by the community. New challenge problems
will promote new developments of provers which will greatly benefit
both developers and users of inductive theorem provers. 

\end{abstract}

\section{Introduction}

We have recently seen increased interest in inductive theorem proving, both with specialised provers such as IsaPlanner, Zeno and HipSpec \cite{dixon2007isaplanner,zeno,hipspecCADE}, SMT-solvers such as Dafny/Z3 and CVC4 \cite{dafny,cvc4}, recent work on the first-order SPASS prover \cite{SPASSInduction}, as well as some support in proof assistants \cite{acl2,hipster}. 

To ease evaluation and development, and compare the relative strengths of the different systems, it is important to have good standard benchmarks. The contribution of this paper is an accessible standard benchmark suite for inductive theorem provers which can be extended by users and developers. The benchmarks are publicly available at: 
\begin{center}
\url{https://github.com/tip-org/benchmarks}
\end{center}
We have so far collected 197 problems in the TIP benchmark suite. We invite the community to submit additional problems and challenges and expect the collection to continuously grow, and provide new challenges for developers. 

We do not yet discuss any special-purpose language features for expressing inductive problems in general. The benchmarks are therefore currently expressed in a subset of the WhyML specification language from the Why3 program verification system \cite{boogie11why3,Why3}. We have chosen this format as the Why3 system already provides translation tools from WhyML to various other common formats, such as SMT-LIB and versions of TPTP. 
In addition, the WhyML language is easy to read also for humans. The Why3 system relies on external provers to discharge proof obligations and is already connected to a wide variety of automated and interactive provers, including  Alt-Ergo, CVC3, Z3, E, SPASS, Vampire, Coq and PVS. We hope that the new benchmark suite will encourage the connection of automated inductive theorem provers to Why3. 

\section{The Benchmark Format}
\label{sec:format}
The basic WhyML language is an extension of first-order logic also featuring e.g. polymorphic types, algebraic datatypes and recursive function definitions over algebraic types. Why3 requires functions to be provably terminating. Recently, WhyML has also been extended with higher-order functions and lambda abstractions \cite{HOWhyML}. For the full definition of the WhyML language we refer to the Why3 webpage: \url{http://why3.lri.fr/}. For the purpose of the TIP benchmark suite we currently support a subset of WhyML summarised below:
\begin{itemize}
\item \textbf{Declarations:} 
	\begin{itemize}
	\item (polymorphic) algebraic datatype declarations
	\item (polymorphic) recursive function definitions
	\end{itemize}
\item \textbf{Expressions:} 
	\begin{itemize}
	\item variables
	\item function application
	\item match (case) expressions
	\item lambda abstraction
	%\item let-expressions (non-recursive, non-polymorphic)
	\end{itemize}
%\item \textbf{Types:}
%	\begin{itemize}
%	\item function arrows
%	\end{itemize}
\end{itemize}	
This subset represent a basic functional programming language and is sufficiently to expressive for our current set of standard benchmarks. Further extensions of the supported subset are likely. 

\subsection*{Example}
As an example of what the benchmarks look like, consider \texttt{prop12} from the IsaPlanner benchmark set (see \ref{sec:isap} below), which states that the functions \texttt{drop} and \texttt{map} distribute over one another: \begin{center} \texttt{drop n (map f xs) = map f (drop n xs)}.\end{center}
Each benchmark lives in a dummy module of its own (here called '\texttt{A}'). As \texttt{map} is a higher-order function, we import the \texttt{HighOrd} module, which is built into Why3. We also declare two simple algebraic datatypes representing natural numbers and polymorphic lists.

\begin{code}
module A
  use HighOrd
  type nat = Z | S nat
  type list 'a = Nil | Cons 'a (list 'a)
\end{code}

Next, we declare two recursive functions: \texttt{drop}, which recursively drops a given number of elements from the front of the list and \texttt{map}, which is a higher-order function applying the given function \texttt{f} to each element of a list.

\begin{code}
function drop (n : nat) (xs : list 'a) : list 'a =
match n with
	| Z -> xs
	| S m ->
		match xs with
		| Nil -> (Nil : list 'a)
		| Cons y ys -> drop m ys
	end
end

function map (f : ('a -> 'b)) (ds : list 'a) : list 'b =
match ds with
	| Nil -> (Nil : list 'b)
	| Cons x xs -> Cons (f x) (map f xs)
end
\end{code}

Finally, the benchmark problem itself is declared with the keyword \texttt{goal} and given the name \texttt{prop\_12}:

\begin{code}
goal prop_12 :
  forall n : nat, f : ('a -> 'b), xs : list 'a .
  drop n (map f xs) = map f (drop n xs)
\end{code}
Each benchmark file is stand-alone and only contains one property. 

\section{Sample Benchmarks}
In this section we give a short overview of  some the problems currently available in the repository. We expect more to be added.

\subsection{IsaPlanner's Rippling and Case-Analysis Benchmarks}
\label{sec:isap}
This set of 85 problems comes from the evaluation of IsaPlanner's rippling-heuristic for guiding rewriting in inductive proofs in the context of functions with case- and if-statements \cite{IsaPcase}. It has been used in the evaluation of many of the recent inductive theorem provers and includes theorems about lists, natural numbers and binary trees. The proofs are relatively easy, most of the theorems can be proved by structural induction using only the function definitions and only 15 require auxiliary lemmas to be discovered.

\subsection{Productive Use of Failure Benchmarks}
This is another benchmark suite which has been used to evaluate several recent provers. It consists of 50 theorems about lists and natural numbers and originates from evaluation of techniques for discovering auxiliary lemmas in the CLAM prover \cite{productiveuse}. The original paper did not provide definitions for the functions used in the benchmarks, so the definitions provided here come from the evaluation of the HipSpec system \cite{hipspecCADE}. These proofs are generally a bit harder, and may require additional lemmas to be found and proved (by another induction) or generalisation of the conjecture in order to strengthen the inductive hypothesis. 

\subsection{New TIP Benchmarks}
This set contains 63 new benchmarks including, amongst others,
properties of the Agda standard
library\footnote{\url{https://github.com/agda/agda-stdlib}}
implementation of integers on top of natural numbers, problems about natural numbers in binary representation, problems about regular expressions, binary search trees, grammars and skew heaps. The problems about regular expressions, grammars and heaps have to our knowledge not been fully automated yet and are offered as challenges!

\section{Contribute to TIP}
We invite the theorem proving community to contribute additional inductive benchmarks and challenge problems to TIP. Instructions for how to submit new problems can be found in the TIP repository README file (see \url{https://github.com/tip-org/benchmarks}).

For automated translation between Haskell and WhyML, HipSpec provides some useful tools which can be found at \url{https://github.com/danr/hipspec/tree/print-why3}.

\section{Conclusion and Further Work}
TIP is intended to be a standard benchmark suite for developers and users of inductive theorem provers. We hope that this initiative will ease comparison and evaluation of systems and spur further collaboration and development by attracting submissions of additional challenge problems from the community. 

In addition to serving as a standard benchmark suite for inductive provers, the TIP benchmarks may also be useful for developers of theory exploration systems. Theory exploration is a technique for automatically discovering interesting conjectures about a given set of functions and datatypes, and is used in for example the HipSpec prover to discover lemmas. The TIP benchmarks can be compared to the output from the theory explorer in precision/recall analysis to assess the quality and interestingness of the conjectures generated. A good theory exploration system may also be used to generate new benchmarks for TIP.

The TIP benchmarks are currently expressed in a subset of WhyML. If we want to use the Why3 translation tools to other formats, there are some restrictions. Functions are for instance required to be provably terminating by the Why3 termination checker, which might not always be the case (e.g. it fails to prove termination for many functions that are not structurally recursive).  
In the future, we therefore expect to support a richer language, and will provide tools to help developers use the TIP format.
We may also want to include problems about lazy functions and will then need to extend the format to also allow non-terminating functions.
%We may in the future perhaps also want to include problems featuring functions in a programming language with lazy evaluation. 
Another extension is to also allow non-theorems among the benchmarks, for evaluation of tools for counter-example finding.  We see this paper as a starting point to encourage further discussion in the inductive theorem proving community about what future format(s) for inductive problems should look like.



\bibliographystyle{plain}
\bibliography{bibfile}

\end{document}
